"""Conversation Flow Controller for managing multi-turn agent interactions.

Orchestrates the conversation flow based on AgentState, handling:
- New task requests
- Parameter gathering
- Confirmation before execution
- Task execution and results

Now with LLM-powered agents (Phase 4) for better context understanding
and natural parameter extraction.
"""

import logging
from dataclasses import dataclass, field
from typing import Any

from app.services.assistant.agent_state import AgentState
from app.services.assistant.router import (
    assistant_router,
    Intent,
    PARAM_QUESTIONS,
    RECOMMENDED_PARAM_QUESTIONS,
    INTENT_TO_AGENTS,
)
from app.services.assistant.user_preferences import UserPreferences
from app.services.assistant.llm_agents import (
    ConversationContext,
    parameter_agent,
    conversation_agent,
)
from app.services.assistant.ux_messages import (
    ux_helper,
    ProgressStage,
    ErrorType,
    FeedbackCollector,
)

logger = logging.getLogger(__name__)


@dataclass
class FlowResponse:
    """Response from the flow controller."""

    # Message content for the user
    content: str

    # Action buttons to show
    actions: list[dict[str, str]] = field(default_factory=list)

    # Tasks to create (when executing)
    tasks_to_create: list[dict[str, Any]] = field(default_factory=list)

    # Updated agent state
    agent_state: AgentState | None = None

    # Whether execution should happen
    should_execute: bool = False

    # Intent for tracking
    intent: str = "unknown"

    # Confidence score
    confidence: float = 0.0

    # All extracted/gathered params
    extracted_params: dict[str, Any] = field(default_factory=dict)

    # Progress tracking (Phase 5: UX improvements)
    progress: dict[str, Any] | None = None

    # Error info if any
    error: dict[str, Any] | None = None

    # Whether to show feedback prompt
    show_feedback: bool = False


class ConversationFlowController:
    """Controller for managing conversation flow with state machine.

    Handles different stages of conversation:
    - idle: Waiting for new request
    - gathering: Collecting required and recommended parameters
    - confirming: Showing summary before execution
    - executing: Task is running
    - completed: Task finished, ready for new requests

    Now supports LLM-powered agents (Phase 4) for better understanding.
    """

    def __init__(self, use_llm: bool = True):
        """Initialize the flow controller.

        Args:
            use_llm: If True, use LLM agents for smarter extraction.
                    Falls back to rule-based if LLM fails.
        """
        self._router = assistant_router
        self._use_llm = use_llm
        self._parameter_agent = parameter_agent
        self._conversation_agent = conversation_agent

    def _build_llm_context(
        self,
        agent_state: AgentState,
        conversation_context: dict[str, Any],
        company_context: dict[str, Any],
    ) -> ConversationContext:
        """Build context object for LLM agents.

        Args:
            agent_state: Current agent state
            conversation_context: Conversation history and params
            company_context: Company information

        Returns:
            ConversationContext for LLM agents
        """
        # Extract messages from context
        messages = []
        for msg in conversation_context.get("messages", [])[-10:]:
            messages.append({
                "role": msg.get("role", "user"),
                "content": msg.get("content", ""),
            })

        return ConversationContext(
            messages=messages,
            current_task=agent_state.current_task,
            gathered_params=agent_state.gathered_params.copy(),
            missing_params=(
                agent_state.missing_required + agent_state.missing_recommended
            ),
            original_request=agent_state.original_request,
            company_name=company_context.get("name"),
            brand_voice=company_context.get("brand", {}).get("voice"),
        )

    async def process(
        self,
        message: str,
        agent_state: AgentState,
        conversation_context: dict[str, Any],
        company_context: dict[str, Any],
        user_preferences: UserPreferences | None = None,
    ) -> FlowResponse:
        """Process a message based on current agent state.

        Args:
            message: User's message
            agent_state: Current state of the agent
            conversation_context: Previous messages, params, etc.
            company_context: Company info for personalization
            user_preferences: Learned user preferences for smart defaults

        Returns:
            FlowResponse with content, actions, and updated state
        """
        stage = agent_state.conversation_stage
        prefs = user_preferences or UserPreferences()

        if stage == "idle":
            return await self._handle_idle(message, agent_state, conversation_context, prefs)

        elif stage == "gathering":
            return await self._handle_gathering(message, agent_state, conversation_context, prefs)

        elif stage == "confirming":
            return await self._handle_confirming(message, agent_state, company_context, prefs)

        elif stage == "executing":
            return await self._handle_executing(message, agent_state)

        elif stage == "completed":
            return await self._handle_completed(message, agent_state, conversation_context, prefs)

        else:
            # Unknown state, reset to idle
            agent_state.reset()
            return await self._handle_idle(message, agent_state, conversation_context, prefs)

    async def _handle_idle(
        self,
        message: str,
        agent_state: AgentState,
        context: dict[str, Any],
        prefs: UserPreferences,
    ) -> FlowResponse:
        """Handle message when in idle state (new request)."""
        # Interpret the new request
        intent_result = await self._router.interpret(message, conversation_context=context)

        # Handle conversational intents using LLM (no task execution needed)
        if intent_result.intent in (Intent.GREETING, Intent.HELP, Intent.CAPABILITIES, Intent.UNKNOWN):
            # Use LLM for intelligent, contextual response
            response_content = await self._generate_conversational_response(
                message=message,
                intent=intent_result.intent,
                context=context,
            )
            return FlowResponse(
                content=response_content,
                agent_state=agent_state,
                intent=intent_result.intent.value,
                confidence=intent_result.confidence,
            )

        # Legacy fallback for UNKNOWN if LLM fails (should not reach here normally)
        if intent_result.intent == Intent.UNKNOWN:
            return FlowResponse(
                content=self._build_unknown_response(),
                agent_state=agent_state,
                intent=intent_result.intent.value,
                confidence=intent_result.confidence,
            )

        # Apply smart defaults from user preferences
        initial_params = intent_result.extracted_params.copy()
        smart_defaults = prefs.get_smart_defaults()

        # Only apply defaults for params not already extracted
        for key, value in smart_defaults.items():
            if key not in initial_params:
                initial_params[key] = value

        # Update recommended_missing based on what we already have from preferences
        missing_recommended = [
            p for p in intent_result.recommended_missing
            if p not in initial_params
        ]

        # Start a new task
        agent_state.start_task(
            task_type=intent_result.intent.value,
            original_request=message,
            initial_params=initial_params,
            missing_required=intent_result.missing_info,
            missing_recommended=missing_recommended,
        )

        # Check what we need to do next
        if agent_state.missing_required:
            # Need required params first
            return self._ask_for_param(
                agent_state,
                agent_state.missing_required[0],
                is_required=True,
                intent=intent_result.intent.value,
                confidence=intent_result.confidence,
            )

        elif agent_state.missing_recommended:
            # Check if user prefers to skip recommendations
            if prefs.should_skip_recommendations():
                # Apply defaults and go directly to confirming/executing
                return self._apply_defaults_and_confirm(agent_state, prefs)

            # Have required, ask for recommended
            return self._ask_for_recommendations(
                agent_state,
                intent=intent_result.intent.value,
                confidence=intent_result.confidence,
                prefs=prefs,
            )

        else:
            # All params present, check auto_approve
            if prefs.auto_approve:
                # Skip confirmation, go directly to execution
                agent_state.transition("quick_execute")
                agent_state.transition("confirmed")
                return self._build_execution_response(agent_state, {})
            else:
                # Go to confirming
                agent_state.transition("quick_execute")
                return self._build_confirmation(
                    agent_state,
                    intent=intent_result.intent.value,
                    confidence=intent_result.confidence,
                )

    async def _handle_gathering(
        self,
        message: str,
        agent_state: AgentState,
        context: dict[str, Any],
        prefs: UserPreferences,
    ) -> FlowResponse:
        """Handle message when gathering parameters."""
        message_lower = message.lower().strip()

        # Check for special commands (support both Polish and ASCII variants)
        use_defaults_commands = [
            "[u≈ºyj domy≈õlnych]", "u≈ºyj domy≈õlnych", "domy≈õlne",
            "[uzyj domyslnych]", "uzyj domyslnych", "domyslne",
            "defaults", "use defaults",
        ]
        if message_lower in use_defaults_commands:
            return self._apply_defaults_and_confirm(agent_state, prefs)

        # Check for "don't ask again" command
        skip_commands = [
            "nie pytaj wiƒôcej", "nie pytaj wiecej", "zapamiƒôtaj",
            "skip always", "always defaults",
        ]
        if message_lower in skip_commands:
            # This would need to be saved via PreferencesService
            # For now, just apply defaults
            return self._apply_defaults_and_confirm(agent_state, prefs)

        if message_lower in ["anuluj", "cancel", "stop"]:
            agent_state.transition("cancel")
            agent_state.reset()
            return FlowResponse(
                content="Anulowano. Jak mogƒô Ci pom√≥c?",
                agent_state=agent_state,
                intent="unknown",
            )

        # Extract parameter value from the response (using LLM when available)
        extracted = await self._extract_param_from_response_async(
            message,
            agent_state.last_question_param,
            agent_state.current_task,
            agent_state,
        )

        # Update gathered params
        for key, value in extracted.items():
            agent_state.add_param(key, value)

        # Check if we need more params
        if agent_state.missing_required:
            return self._ask_for_param(
                agent_state,
                agent_state.missing_required[0],
                is_required=True,
                intent=agent_state.current_task or "unknown",
            )

        elif agent_state.missing_recommended:
            return self._ask_for_recommendations(
                agent_state,
                intent=agent_state.current_task or "unknown",
                prefs=prefs,
            )

        else:
            # All done gathering, move to confirming
            agent_state.transition("params_complete")

            # Check auto_approve preference
            if prefs.auto_approve:
                agent_state.transition("confirmed")
                return self._build_execution_response(agent_state, {})

            return self._build_confirmation(
                agent_state,
                intent=agent_state.current_task or "unknown",
            )

    async def _handle_confirming(
        self,
        message: str,
        agent_state: AgentState,
        company_context: dict[str, Any],
        prefs: UserPreferences,
    ) -> FlowResponse:
        """Handle message when confirming parameters."""
        message_lower = message.lower().strip()

        # Check for confirmation
        if message_lower in ["tak", "ok", "dobrze", "zatwierd≈∫", "wykonaj", "start", "generuj"]:
            agent_state.transition("confirmed")
            return self._build_execution_response(agent_state, company_context)

        # Check for undo request (Phase 5: UX)
        if message_lower in ["cofnij", "undo", "wr√≥ƒá", "poprzedni"]:
            if agent_state.undo_last_change():
                return FlowResponse(
                    content="‚Ü©Ô∏è Cofniƒôto ostatniƒÖ zmianƒô.\n\n" + self._format_params_preview(agent_state.gathered_params),
                    actions=[
                        {"id": "confirm", "label": "‚úÖ Wykonaj", "type": "primary"},
                        {"id": "modify", "label": "‚úèÔ∏è Zmie≈Ñ", "type": "secondary"},
                        {"id": "undo", "label": "‚Ü©Ô∏è Cofnij", "type": "ghost"} if agent_state.can_undo() else {"id": "cancel", "label": "‚ùå Anuluj", "type": "ghost"},
                    ],
                    agent_state=agent_state,
                    intent=agent_state.current_task or "unknown",
                    extracted_params=agent_state.gathered_params,
                )
            else:
                return FlowResponse(
                    content="Nie ma czego cofaƒá. Brak historii zmian.",
                    agent_state=agent_state,
                    intent=agent_state.current_task or "unknown",
                    extracted_params=agent_state.gathered_params,
                )

        # Check for modification request
        if message_lower in ["nie", "zmie≈Ñ", "popraw", "edytuj", "modyfikuj"]:
            agent_state.transition("modify")
            # Save current state for undo
            agent_state.save_params_snapshot()
            # Ask what to change
            return FlowResponse(
                content="‚úèÔ∏è Co chcesz zmieniƒá? Mo≈ºesz podaƒá nowe warto≈õci dla parametr√≥w.\n\nüí° Wpisz **cofnij** aby przywr√≥ciƒá poprzednie warto≈õci.",
                agent_state=agent_state,
                intent=agent_state.current_task or "unknown",
                extracted_params=agent_state.gathered_params,
            )

        # Check for cancel
        if message_lower in ["anuluj", "cancel", "stop"]:
            agent_state.transition("cancel")
            agent_state.reset()
            error_info = ux_helper.get_error_response(ErrorType.CANCELLED)
            return FlowResponse(
                content=f"{error_info['message']} Jak mogƒô Ci pom√≥c?",
                agent_state=agent_state,
                intent="unknown",
            )

        # Try to extract changes from the message (using LLM when available)
        extracted = await self._extract_param_from_response_async(
            message,
            None,  # No specific param expected
            agent_state.current_task,
            agent_state,
        )

        if extracted:
            # User provided new values, update and re-confirm
            for key, value in extracted.items():
                agent_state.gathered_params[key] = value

            return self._build_confirmation(
                agent_state,
                intent=agent_state.current_task or "unknown",
            )

        # Unclear response, ask for clarification
        return FlowResponse(
            content=(
                "Nie rozumiem. Powiedz:\n"
                "‚Ä¢ **tak** - aby wykonaƒá zadanie\n"
                "‚Ä¢ **zmie≈Ñ** - aby zmodyfikowaƒá parametry\n"
                "‚Ä¢ **anuluj** - aby anulowaƒá"
            ),
            agent_state=agent_state,
            intent=agent_state.current_task or "unknown",
            extracted_params=agent_state.gathered_params,
        )

    async def _handle_executing(
        self,
        message: str,
        agent_state: AgentState,
    ) -> FlowResponse:
        """Handle message when task is executing."""
        # Task is running, user can check status or wait
        return FlowResponse(
            content="Zadanie jest w trakcie wykonywania. Proszƒô czekaƒá...",
            agent_state=agent_state,
            intent=agent_state.current_task or "unknown",
            extracted_params=agent_state.gathered_params,
        )

    async def _handle_completed(
        self,
        message: str,
        agent_state: AgentState,
        context: dict[str, Any],
        prefs: UserPreferences,
    ) -> FlowResponse:
        """Handle message after task completion."""
        # Check if user wants to start something new
        agent_state.transition("reset")
        agent_state.reset()

        # Process as new request
        return await self._handle_idle(message, agent_state, context, prefs)

    def _ask_for_param(
        self,
        agent_state: AgentState,
        param: str,
        is_required: bool,
        intent: str,
        confidence: float = 1.0,
    ) -> FlowResponse:
        """Build response asking for a specific parameter."""
        if is_required:
            question = PARAM_QUESTIONS.get(param, f"Podaj {param}:")
        else:
            question = RECOMMENDED_PARAM_QUESTIONS.get(param, f"Podaj {param}:")

        agent_state.set_question(question, param)

        return FlowResponse(
            content=question,
            agent_state=agent_state,
            intent=intent,
            confidence=confidence,
            extracted_params=agent_state.gathered_params,
        )

    def _ask_for_recommendations(
        self,
        agent_state: AgentState,
        intent: str,
        confidence: float = 1.0,
        prefs: UserPreferences | None = None,
    ) -> FlowResponse:
        """Ask for all recommended parameters at once."""
        questions = []
        for param in agent_state.missing_recommended:
            q = RECOMMENDED_PARAM_QUESTIONS.get(param, f"Podaj {param}")
            questions.append(f"‚Ä¢ {q}")

        content = "Chcƒô stworzyƒá najlepszy wynik! Doprecyzuj:\n\n"
        content += "\n".join(questions)
        content += "\n\nMo≈ºesz te≈º u≈ºyƒá domy≈õlnych ustawie≈Ñ."

        # Show learned preferences hint if available
        if prefs and prefs.total_tasks > 0:
            smart_defaults = prefs.get_smart_defaults()
            hints = []
            for param in agent_state.missing_recommended:
                if param in smart_defaults:
                    hints.append(f"{param}: {smart_defaults[param]}")
            if hints:
                content += f"\n\nüí° Twoje typowe ustawienia: {', '.join(hints)}"

        # Track that we asked about recommendations
        agent_state.set_question(content, "recommendations")

        actions = [
            {"id": "use_defaults", "label": "U≈ºyj domy≈õlnych", "type": "secondary"},
        ]

        # Add "don't ask again" option for experienced users
        if prefs and prefs.total_tasks >= 3:
            actions.append({
                "id": "skip_always",
                "label": "Nie pytaj wiƒôcej",
                "type": "ghost",
            })

        return FlowResponse(
            content=content,
            actions=actions,
            agent_state=agent_state,
            intent=intent,
            confidence=confidence,
            extracted_params=agent_state.gathered_params,
        )

    def _apply_defaults_and_confirm(
        self,
        agent_state: AgentState,
        prefs: UserPreferences | None = None,
    ) -> FlowResponse:
        """Apply default values for recommended params and move to confirm."""
        # First try user's learned preferences
        if prefs:
            smart_defaults = prefs.get_smart_defaults()
            for param in list(agent_state.missing_recommended):
                if param in smart_defaults:
                    agent_state.add_param(param, smart_defaults[param])

        # Then fill remaining with system defaults
        try:
            intent_enum = Intent(agent_state.current_task)
            defaults = self._router.get_default_params(intent_enum)

            for param in list(agent_state.missing_recommended):
                if param in defaults:
                    agent_state.add_param(param, defaults[param])
        except (ValueError, KeyError):
            pass

        agent_state.transition("use_defaults")
        return self._build_confirmation(
            agent_state,
            intent=agent_state.current_task or "unknown",
        )

    def _build_confirmation(
        self,
        agent_state: AgentState,
        intent: str,
        confidence: float = 1.0,
    ) -> FlowResponse:
        """Build confirmation message showing all parameters."""
        params = agent_state.gathered_params

        # Use UX helper for better formatting
        content = ux_helper.format_confirmation_message(intent, params)

        # Add progress indicator
        progress = ux_helper.get_progress_update(
            ProgressStage.CONFIRMING,
            task_type=intent,
        )

        return FlowResponse(
            content=content,
            actions=[
                {"id": "confirm", "label": "‚úÖ Wykonaj", "type": "primary"},
                {"id": "modify", "label": "‚úèÔ∏è Zmie≈Ñ", "type": "secondary"},
                {"id": "cancel", "label": "‚ùå Anuluj", "type": "ghost"},
            ],
            agent_state=agent_state,
            intent=intent,
            confidence=confidence,
            extracted_params=params,
            progress={
                "stage": progress.stage.value,
                "message": progress.message,
                "percentage": progress.percentage,
            },
        )

    def _build_execution_response(
        self,
        agent_state: AgentState,
        company_context: dict[str, Any],
    ) -> FlowResponse:
        """Build response for starting execution."""
        params = agent_state.gathered_params
        intent = agent_state.current_task or "unknown"

        # Build tasks to create
        tasks_to_create = self._build_tasks(intent, params)

        # Get progress indicator
        progress = ux_helper.get_progress_update(
            ProgressStage.EXECUTING,
            task_type=intent,
        )

        content = f"{progress.message}\n\n"
        content += self._format_params_preview(params)

        return FlowResponse(
            content=content,
            tasks_to_create=tasks_to_create,
            agent_state=agent_state,
            should_execute=True,
            intent=intent,
            confidence=1.0,
            extracted_params=params,
            progress={
                "stage": progress.stage.value,
                "message": progress.message,
                "percentage": progress.percentage,
            },
            show_feedback=True,  # Show feedback after completion
        )

    def _build_tasks(self, intent: str, params: dict[str, Any]) -> list[dict[str, Any]]:
        """Build task creation info based on intent and params."""
        try:
            intent_enum = Intent(intent)
            agents = INTENT_TO_AGENTS.get(intent_enum, [])
        except ValueError:
            return []

        tasks = []
        for agent in agents:
            task_info = self._build_task_info(agent, intent, params)
            if task_info:
                tasks.append(task_info)

        return tasks

    def _build_task_info(
        self,
        agent: str,
        intent: str,
        params: dict[str, Any],
    ) -> dict[str, Any] | None:
        """Build task creation info for a specific agent."""
        task_configs = {
            "instagram_specialist": {
                "department": "marketing",
                "type": "create_post",
                "input_mapping": {
                    "brief": params.get("topic", params.get("brief", "")),
                    "post_type": params.get("post_type", "post"),
                    "include_hashtags": True,
                    "platform": params.get("platform", "instagram"),
                    "tone": params.get("tone", "profesjonalny"),
                    "target_audience": params.get("target_audience", "og√≥lna"),
                },
            },
            "copywriter": {
                "department": "marketing",
                "type": "create_copy",
                "input_mapping": {
                    "brief": params.get("topic", params.get("brief", "")),
                    "copy_type": params.get("copy_type", "ad"),
                    "tone": params.get("tone", "profesjonalny"),
                    "target_audience": params.get("target_audience", "og√≥lna"),
                },
            },
            "invoice_specialist": {
                "department": "finance",
                "type": "create_invoice",
                "input_mapping": {
                    "client_name": params.get("client_name", ""),
                    "items": params.get("items", []),
                    "due_date": params.get("due_date", "14 dni"),
                    "payment_terms": params.get("payment_terms", "przelew"),
                },
            },
        }

        config = task_configs.get(agent)
        if not config:
            return None

        return {
            "agent": agent,
            "department": config["department"],
            "type": config["type"],
            "input": config["input_mapping"],
        }

    async def _extract_param_from_response_async(
        self,
        message: str,
        expected_param: str | None,
        task_type: str | None,
        agent_state: AgentState,
    ) -> dict[str, Any]:
        """Extract parameter values from user's response using LLM agent.

        Args:
            message: User's message
            expected_param: The parameter we asked about
            task_type: Current task type
            agent_state: Current agent state with context

        Returns:
            Dictionary of extracted parameters
        """
        if self._use_llm:
            try:
                # Use LLM parameter agent for smarter extraction
                result = await self._parameter_agent.extract(
                    message=message,
                    task_type=task_type,
                    existing_params=agent_state.gathered_params,
                    missing_params=agent_state.missing_required + agent_state.missing_recommended,
                    last_question_param=expected_param,
                )

                extracted = result.get("extracted", {})
                if extracted:
                    logger.debug(f"LLM extracted params: {extracted}")
                    return extracted

            except Exception as e:
                logger.warning(f"LLM parameter extraction failed: {e}")

        # Fallback to rule-based extraction
        return self._extract_param_from_response(message, expected_param, task_type)

    def _extract_param_from_response(
        self,
        message: str,
        expected_param: str | None,
        task_type: str | None,
    ) -> dict[str, Any]:
        """Extract parameter values from user's response (rule-based fallback)."""
        try:
            if task_type:
                intent = Intent(task_type)
            else:
                intent = Intent.UNKNOWN
        except ValueError:
            intent = Intent.UNKNOWN

        # Use the router's extraction
        extracted = self._router.extract_params_from_message(
            message, intent, is_followup=True
        )

        return extracted

    def _format_params_preview(self, params: dict[str, Any]) -> str:
        """Format parameters for display."""
        labels = {
            "topic": "Temat",
            "brief": "Temat",
            "post_type": "Typ",
            "platform": "Platforma",
            "copy_type": "Rodzaj tekstu",
            "client_name": "Klient",
            "tone": "Ton",
            "target_audience": "Grupa docelowa",
            "campaign_goal": "Cel kampanii",
            "salary_range": "Wynagrodzenie",
            "location": "Lokalizacja",
            "remote_option": "Praca zdalna",
            "due_date": "Termin p≈Çatno≈õci",
            "payment_terms": "Warunki p≈Çatno≈õci",
        }

        value_labels = {
            "post": "post",
            "story": "story",
            "reel": "reel",
            "instagram": "Instagram",
            "facebook": "Facebook",
            "linkedin": "LinkedIn",
            "profesjonalny": "profesjonalny",
            "casualowy": "casualowy",
            "zabawny": "zabawny",
            "og√≥lna": "og√≥lna",
        }

        lines = ["üìã **Parametry:**"]
        for key, value in params.items():
            if value and key in labels:
                display_value = value_labels.get(value, value) if isinstance(value, str) else value
                # Truncate long values
                if isinstance(display_value, str) and len(display_value) > 50:
                    display_value = display_value[:50] + "..."
                lines.append(f"‚Ä¢ {labels[key]}: {display_value}")

        return "\n".join(lines) if len(lines) > 1 else ""

    async def _generate_conversational_response(
        self,
        message: str,
        intent: Intent,
        context: dict[str, Any],
    ) -> str:
        """Generate intelligent conversational response using LLM.

        Args:
            message: User's message
            intent: Detected intent type
            context: Conversation context

        Returns:
            AI-generated response string
        """
        try:
            # Build context for the conversation agent
            conv_context = ConversationContext(
                messages=context.get("messages", []),
                current_task=None,
                gathered_params={},
                missing_params=[],
            )

            # Create a specialized prompt for general conversation
            system_prompt = self._build_conversational_system_prompt(intent)

            # Use the conversation agent's LLM
            from langchain_core.messages import SystemMessage, HumanMessage

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=message),
            ]

            response = await conversation_agent.llm.ainvoke(messages)
            return response.content

        except Exception as e:
            logger.warning(f"LLM conversation failed: {e}, using fallback")
            # Fallback to hardcoded responses
            if intent == Intent.GREETING:
                return self._build_greeting_response()
            elif intent == Intent.HELP:
                return self._build_help_response()
            elif intent == Intent.CAPABILITIES:
                domain = self._detect_domain_from_message(message)
                return self._build_capabilities_response(domain)
            else:
                return self._build_unknown_response()

    def _build_conversational_system_prompt(self, intent: Intent) -> str:
        """Build system prompt for conversational responses."""
        base_info = """Jeste≈õ Agora - inteligentnym asystentem AI dla firm. Twoje mo≈ºliwo≈õci:

**MARKETING:**
- Tworzenie post√≥w na social media (Instagram, Facebook, LinkedIn)
- Pisanie tekst√≥w reklamowych, slogan√≥w, opis√≥w produkt√≥w
- Planowanie kampanii marketingowych
- Generowanie grafik do post√≥w

**FINANSE:**
- Generowanie profesjonalnych faktur VAT
- Analiza przep≈Çyw√≥w finansowych (cashflow)
- Planowanie bud≈ºetu

**HR:**
- Tworzenie og≈Çosze≈Ñ o pracƒô
- Przygotowanie pyta≈Ñ rekrutacyjnych
- Materia≈Çy onboardingowe dla nowych pracownik√≥w

**PRAWO:**
- Analiza um√≥w i kontrakt√≥w
- Tworzenie polityki prywatno≈õci
- Regulaminy i warunki us≈Çug
- Weryfikacja zgodno≈õci z RODO/GDPR

**SPRZEDA≈ª:**
- Przygotowanie ofert handlowych
- Lead scoring - ocena potencjalnych klient√≥w
- Emaile follow-up do klient√≥w

**OBS≈ÅUGA KLIENTA:**
- Odpowiedzi na zg≈Çoszenia i reklamacje
- Tworzenie bazy FAQ
- Analiza sentymentu opinii klient√≥w"""

        if intent == Intent.GREETING:
            return f"""{base_info}

U≈ºytkownik siƒô wita. Odpowiedz przyja≈∫nie, kr√≥tko przedstaw siƒô i zapytaj jak mo≈ºesz pom√≥c.
BƒÖd≈∫ naturalny, nie wymieniaj wszystkich funkcji - po prostu przywitaj siƒô ciep≈Ço.
Odpowiadaj po polsku."""

        elif intent == Intent.HELP:
            return f"""{base_info}

U≈ºytkownik prosi o pomoc lub instrukcje. Wyja≈õnij jak korzystaƒá z asystenta:
- Wystarczy opisaƒá czego potrzebuje naturalnym jƒôzykiem
- Mo≈ºesz podaƒá 2-3 przyk≈Çady u≈ºycia
- BƒÖd≈∫ pomocny i zachƒôcajƒÖcy
Odpowiadaj po polsku."""

        elif intent == Intent.CAPABILITIES:
            return f"""{base_info}

U≈ºytkownik pyta o Twoje mo≈ºliwo≈õci. Odpowiedz na konkretne pytanie:
- Je≈õli pyta og√≥lnie - daj przeglƒÖd g≈Ç√≥wnych obszar√≥w
- Je≈õli pyta o konkretny obszar (np. finanse) - opisz szczeg√≥≈Çowo ten obszar
- Podaj 1-2 przyk≈Çady u≈ºycia dla danego obszaru
Odpowiadaj po polsku, u≈ºywaj emoji dla lepszej czytelno≈õci."""

        else:  # UNKNOWN
            return f"""{base_info}

Nie rozpoznano konkretnego zadania w wiadomo≈õci u≈ºytkownika.
Spr√≥buj zrozumieƒá co u≈ºytkownik chce osiƒÖgnƒÖƒá i:
1. Je≈õli to pytanie - odpowiedz na nie
2. Je≈õli to pro≈õba niejasna - dopytaj o szczeg√≥≈Çy
3. Je≈õli to rozmowa - prowad≈∫ jƒÖ naturalnie

NIE m√≥w "nie rozumiem" - zawsze staraj siƒô pom√≥c.
Je≈õli naprawdƒô nie wiesz o co chodzi, zaproponuj przyk≈Çady tego co mo≈ºesz zrobiƒá.
Odpowiadaj po polsku, bƒÖd≈∫ pomocny i naturalny."""

    def _build_greeting_response(self) -> str:
        """Build friendly greeting response (fallback)."""
        return (
            "Cze≈õƒá! üëã Jestem **Agora** - Tw√≥j asystent biznesowy.\n\n"
            "Mogƒô pom√≥c Ci z:\n"
            "‚Ä¢ üì± **Marketing** - posty, teksty reklamowe, kampanie\n"
            "‚Ä¢ üí∞ **Finanse** - faktury, analizy cashflow\n"
            "‚Ä¢ üë• **HR** - og≈Çoszenia o pracƒô, onboarding\n"
            "‚Ä¢ ‚öñÔ∏è **Prawo** - umowy, regulaminy, RODO\n"
            "‚Ä¢ üéØ **Sprzeda≈º** - oferty, follow-upy, lead scoring\n\n"
            "Po prostu powiedz mi czego potrzebujesz!"
        )

    def _build_help_response(self) -> str:
        """Build help response with usage instructions."""
        return (
            "**Jak mogƒô Ci pom√≥c?** ü§ù\n\n"
            "Po prostu napisz czego potrzebujesz, np.:\n"
            "‚Ä¢ *\"Stw√≥rz post na Instagram o nowej kawie\"*\n"
            "‚Ä¢ *\"Wygeneruj fakturƒô dla klienta ABC\"*\n"
            "‚Ä¢ *\"Napisz og≈Çoszenie o pracƒô na stanowisko programisty\"*\n\n"
            "Zadam Ci kilka pyta≈Ñ, ≈ºeby doprecyzowaƒá szczeg√≥≈Çy, "
            "a potem wykonam zadanie.\n\n"
            "üí° **Wskaz√≥wka**: Mo≈ºesz te≈º zapytaƒá *\"co mo≈ºesz zrobiƒá w kwestii finans√≥w?\"* "
            "≈ºeby poznaƒá moje mo≈ºliwo≈õci w danym obszarze."
        )

    def _detect_domain_from_message(self, message: str) -> str | None:
        """Detect which domain the user is asking about."""
        message_lower = message.lower()

        if any(word in message_lower for word in ["finans", "faktur", "cashflow", "pieniƒÖdz", "bud≈ºet"]):
            return "finance"
        if any(word in message_lower for word in ["market", "reklam", "post", "social", "instagram"]):
            return "marketing"
        if any(word in message_lower for word in ["hr", "rekrutac", "pracownik", "zatrudn", "onboard"]):
            return "hr"
        if any(word in message_lower for word in ["praw", "umow", "regulamin", "rodo", "gdpr"]):
            return "legal"
        if any(word in message_lower for word in ["sprzeda≈º", "ofert", "klient", "lead", "handl"]):
            return "sales"
        if any(word in message_lower for word in ["support", "obs≈Çug", "ticket", "zg≈Çoszeni"]):
            return "support"

        return None

    def _build_capabilities_response(self, domain: str | None = None) -> str:
        """Build response describing capabilities, optionally for specific domain."""

        capabilities = {
            "marketing": (
                "**üì± Marketing - moje mo≈ºliwo≈õci:**\n\n"
                "‚Ä¢ **Posty social media** - Instagram, Facebook, LinkedIn z hashtagami i grafikƒÖ\n"
                "‚Ä¢ **Teksty reklamowe** - copy, slogany, opisy produkt√≥w\n"
                "‚Ä¢ **Kampanie** - pe≈Çne pakiety materia≈Ç√≥w marketingowych\n"
                "‚Ä¢ **Newsletter** - tre≈õci emailowe\n\n"
                "Przyk≈Çad: *\"Stw√≥rz post na Instagram o promocji -20%\"*"
            ),
            "finance": (
                "**üí∞ Finanse - moje mo≈ºliwo≈õci:**\n\n"
                "‚Ä¢ **Faktury** - generowanie profesjonalnych faktur z VAT\n"
                "‚Ä¢ **Analiza cashflow** - przeglƒÖd przep≈Çyw√≥w finansowych\n"
                "‚Ä¢ **Bud≈ºetowanie** - planowanie wydatk√≥w\n\n"
                "Przyk≈Çad: *\"Wygeneruj fakturƒô dla firmy ABC na 5000 z≈Ç\"*"
            ),
            "hr": (
                "**üë• HR - moje mo≈ºliwo≈õci:**\n\n"
                "‚Ä¢ **Og≈Çoszenia o pracƒô** - profesjonalne oferty zatrudnienia\n"
                "‚Ä¢ **Pytania rekrutacyjne** - zestawy na rozmowy kwalifikacyjne\n"
                "‚Ä¢ **Onboarding** - materia≈Çy powitalne dla nowych pracownik√≥w\n\n"
                "Przyk≈Çad: *\"Napisz og≈Çoszenie o pracƒô dla programisty Python\"*"
            ),
            "legal": (
                "**‚öñÔ∏è Prawo - moje mo≈ºliwo≈õci:**\n\n"
                "‚Ä¢ **Analiza um√≥w** - przeglƒÖd i uwagi do kontrakt√≥w\n"
                "‚Ä¢ **Polityka prywatno≈õci** - dokumenty RODO/GDPR\n"
                "‚Ä¢ **Regulaminy** - warunki korzystania z us≈Çug\n"
                "‚Ä¢ **Weryfikacja RODO** - sprawdzenie zgodno≈õci\n\n"
                "Przyk≈Çad: *\"Sprawd≈∫ zgodno≈õƒá mojej strony z RODO\"*"
            ),
            "sales": (
                "**üéØ Sprzeda≈º - moje mo≈ºliwo≈õci:**\n\n"
                "‚Ä¢ **Oferty handlowe** - propozycje i wyceny\n"
                "‚Ä¢ **Lead scoring** - ocena potencjalnych klient√≥w\n"
                "‚Ä¢ **Follow-up** - emaile przypominajƒÖce do klient√≥w\n\n"
                "Przyk≈Çad: *\"Przygotuj ofertƒô handlowƒÖ dla klienta XYZ\"*"
            ),
            "support": (
                "**üéß Obs≈Çuga klienta - moje mo≈ºliwo≈õci:**\n\n"
                "‚Ä¢ **Odpowiedzi na zg≈Çoszenia** - profesjonalne odpowiedzi\n"
                "‚Ä¢ **FAQ** - baza najczƒô≈õciej zadawanych pyta≈Ñ\n"
                "‚Ä¢ **Analiza sentymentu** - ocena opinii klient√≥w\n\n"
                "Przyk≈Çad: *\"Napisz odpowied≈∫ na reklamacjƒô klienta\"*"
            ),
        }

        if domain and domain in capabilities:
            return capabilities[domain]

        # General overview
        return (
            "**Oto co mogƒô dla Ciebie zrobiƒá:** üöÄ\n\n"
            "üì± **Marketing**\n"
            "Posty social media, teksty reklamowe, kampanie\n\n"
            "üí∞ **Finanse**\n"
            "Faktury, analizy cashflow, bud≈ºetowanie\n\n"
            "üë• **HR**\n"
            "Og≈Çoszenia o pracƒô, rekrutacja, onboarding\n\n"
            "‚öñÔ∏è **Prawo**\n"
            "Umowy, regulaminy, RODO\n\n"
            "üéØ **Sprzeda≈º**\n"
            "Oferty, lead scoring, follow-upy\n\n"
            "üéß **Obs≈Çuga klienta**\n"
            "Odpowiedzi na zg≈Çoszenia, FAQ\n\n"
            "üí° Zapytaj np. *\"co mo≈ºesz zrobiƒá w kwestii marketingu?\"* "
            "≈ºeby poznaƒá szczeg√≥≈Çy danego obszaru."
        )

    def _build_unknown_response(self) -> str:
        """Build response for unknown intent."""
        # Use UX helper for consistent error messaging
        error_info = ux_helper.get_error_response(ErrorType.UNKNOWN_INTENT)

        content = f"**{error_info['title']}**\n\n{error_info['message']}\n\n"

        if error_info.get('suggestions'):
            content += "Spr√≥buj na przyk≈Çad:\n"
            for suggestion in error_info['suggestions'][:4]:
                content += f"‚Ä¢ {suggestion}\n"

        return content


# Singleton instance
flow_controller = ConversationFlowController()
